#!/usr/bin/env python3
"""í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ê°€ ìŠ¤í¬ë¦½íŠ¸"""
import httpx
import asyncio

BASE_URL = "http://localhost:8000/api/v1/huggingface/"

# í…ŒìŠ¤íŠ¸ ë°ì´í„°
test_models = [
    {
        "model_id": "black-forest-labs/FLUX.1-dev",
        "model_name": "FLUX.1 Dev",
        "author": "black-forest-labs",
        "description": "ìµœì²¨ë‹¨ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸. Stable Diffusionì„ ë›°ì–´ë„˜ëŠ” ì„±ëŠ¥",
        "task": "text-to-image",
        "tags": ["diffusion", "image-generation", "flux"],
        "library_name": "diffusers",
        "downloads": 2800000,
        "likes": 8950,
        "url": "https://huggingface.co/black-forest-labs/FLUX.1-dev"
    },
    {
        "model_id": "openai/whisper-large-v3",
        "model_name": "Whisper Large V3",
        "author": "openai",
        "description": "OpenAIì˜ ìµœì‹  ìŒì„± ì¸ì‹ ëª¨ë¸. ë‹¤êµ­ì–´ ì§€ì›",
        "task": "automatic-speech-recognition",
        "tags": ["whisper", "audio", "asr"],
        "library_name": "transformers",
        "downloads": 5200000,
        "likes": 12300,
        "url": "https://huggingface.co/openai/whisper-large-v3"
    },
    {
        "model_id": "Qwen/Qwen2.5-72B-Instruct",
        "model_name": "Qwen 2.5 72B Instruct",
        "author": "Qwen",
        "description": "Alibabaì˜ ê°•ë ¥í•œ ë‹¤êµ­ì–´ LLM. í•œêµ­ì–´ ì§€ì› ìš°ìˆ˜",
        "task": "text-generation",
        "tags": ["qwen", "multilingual", "conversational"],
        "library_name": "transformers",
        "downloads": 980000,
        "likes": 3420,
        "url": "https://huggingface.co/Qwen/Qwen2.5-72B-Instruct"
    },
    {
        "model_id": "runwayml/stable-diffusion-v1-5",
        "model_name": "Stable Diffusion v1.5",
        "author": "runwayml",
        "description": "ê°€ì¥ ì¸ê¸° ìˆëŠ” ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸",
        "task": "text-to-image",
        "tags": ["stable-diffusion", "image-generation"],
        "library_name": "diffusers",
        "downloads": 15600000,
        "likes": 25800,
        "url": "https://huggingface.co/runwayml/stable-diffusion-v1-5"
    },
    {
        "model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "model_name": "Mixtral 8x7B Instruct",
        "author": "mistralai",
        "description": "Mixture of Experts ì•„í‚¤í…ì²˜ì˜ ê°•ë ¥í•œ LLM",
        "task": "text-generation",
        "tags": ["mixtral", "moe", "instruct"],
        "library_name": "transformers",
        "downloads": 3200000,
        "likes": 9100,
        "url": "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1"
    }
]


async def add_models():
    """ëª¨ë¸ ë°ì´í„° ì¶”ê°€"""
    async with httpx.AsyncClient() as client:
        for model in test_models:
            try:
                response = await client.post(BASE_URL, json=model)
                if response.status_code == 201:
                    data = response.json()
                    print(f"âœ… ì¶”ê°€ ì„±ê³µ: {data['model_name']} (ID: {data['id']})")
                elif response.status_code == 400:
                    print(f"âš ï¸  ì´ë¯¸ ì¡´ì¬: {model['model_name']}")
                else:
                    print(f"âŒ ì‹¤íŒ¨: {model['model_name']} - {response.status_code}")
            except Exception as e:
                print(f"âŒ ì—ëŸ¬: {model['model_name']} - {e}")


async def get_models():
    """ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    async with httpx.AsyncClient() as client:
        response = await client.get(BASE_URL)
        data = response.json()
        print(f"\nğŸ“Š ì´ {data['total']}ê°œ ëª¨ë¸")
        for item in data['items']:
            print(f"  - {item['model_name']} (ğŸ‘ {item['likes']:,})")


async def main():
    print("ğŸš€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ê°€ ì‹œì‘...\n")
    await add_models()
    await get_models()
    print("\nâœ¨ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(main())
