"""AI ì •ì±… ë° ê·œì œ ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤"""
import re
from typing import List, Dict
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
import feedparser
from datetime import datetime

from app.models.policy import AIPolicy
from app.services.ai_summary_service import AISummaryService


class PolicyService:
    """AI ì •ì±… ì„œë¹„ìŠ¤"""

    # Curated AI policy data from Gemini deep research (2026-02)
    CURATED_POLICIES = [
        # â”€â”€ í•œêµ­ â”€â”€
        {
            "title": "ì¸ê³µì§€ëŠ¥ ë°œì „ê³¼ ì‹ ë¢° ê¸°ë°˜ ì¡°ì„± ë“±ì— ê´€í•œ ê¸°ë³¸ë²• (AI ê¸°ë³¸ë²•)",
            "policy_type": "Legislation",
            "country": "South Korea",
            "status": "Enacted",
            "description": "2026ë…„ 1ì›” 22ì¼ ì‹œí–‰. ê³ ì˜í–¥ AI(ì˜ë£ŒÂ·ì±„ìš©Â·ëŒ€ì¶œ ë“±) ê´€ë¦¬ ì˜ë¬´í™”, ìƒì„±í˜• AI ì›Œí„°ë§ˆí¬ í‘œì‹œ ì˜ë¬´(ì œ31ì¡°), "
                           "ì¸ê³µì§€ëŠ¥ì•ˆì „ì—°êµ¬ì†Œ ì„¤ë¦½, AI ì‚¬ì—…ìì˜ ì´ìš©ì ê³ ì§€ ì˜ë¬´. EU AI Actì™€ ìœ ì‚¬í•œ ìœ„í—˜ ê¸°ë°˜ ì ‘ê·¼ì´ë‚˜ "
                           "ì²˜ë²Œ ìˆ˜ìœ„ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë‚®ìŒ(ìµœëŒ€ 3ì²œë§Œì› ê³¼íƒœë£Œ). ë²•ë¥  ì œ20676í˜¸.",
            "source_url": "https://www.law.go.kr/ë²•ë ¹/ì¸ê³µì§€ëŠ¥ë°œì „ê³¼ì‹ ë¢°ê¸°ë°˜ì¡°ì„±ë“±ì—ê´€í•œê¸°ë³¸ë²•",
            "impact_areas": ["Healthcare", "Finance", "Hiring", "Public Services"],
            "is_trending": True,
        },
        {
            "title": "2025ë…„ ê°œì¸ì •ë³´ë³´í˜¸ìœ„ì›íšŒ ì£¼ìš” ì •ì±… ì¶”ì§„ê³„íš",
            "policy_type": "Guideline",
            "country": "South Korea",
            "status": "Active",
            "description": "AI ê°œë°œì— ì›ë³¸ ë°ì´í„° í™œìš©ì„ í—ˆìš©í•˜ëŠ” 'AI íŠ¹ë¡€' ë§ˆë ¨, ë¹„ì •í˜• ë°ì´í„°(í…ìŠ¤íŠ¸Â·ì´ë¯¸ì§€ ë“±)ì˜ "
                           "ê°€ëª…ì²˜ë¦¬ ê°€ì´ë“œë¼ì¸ ê³ ë„í™”, ë§ˆì´ë°ì´í„° ì „ ë¶„ì•¼ í™•ì‚°. 2025ë…„ 1ì›” 13ì¼ ë°œí‘œ.",
            "source_url": "https://www.pipc.go.kr/np/cop/bbs/selectBoardArticle.do",
            "impact_areas": ["Privacy", "Data Protection", "AI Development"],
            "is_trending": True,
        },
        {
            "title": "ì¸ê³µì§€ëŠ¥ íˆ¬ëª…ì„± í™•ë³´ ì•ˆë‚´ ì§€ì¹¨",
            "policy_type": "Guideline",
            "country": "South Korea",
            "status": "Active",
            "description": "AI ê¸°ë³¸ë²• ì‹œí–‰(2026-01-22)ì— ë§ì¶˜ ì‚¬ì—…ììš© ê°€ì´ë“œ. ì›Œí„°ë§ˆí¬ ê¸°ìˆ  í‘œì¤€ ë° í‘œì‹œ ë°©ë²• ì œì‹œ. "
                           "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ ë°œí‘œ.",
            "source_url": "https://www.msit.go.kr",
            "impact_areas": ["Transparency", "Watermarking", "Compliance"],
            "is_trending": True,
        },
        # â”€â”€ EU â”€â”€
        {
            "title": "EU AI Act",
            "policy_type": "Regulation",
            "country": "European Union",
            "status": "Enacted",
            "description": "ì„¸ê³„ ìµœì´ˆì˜ í¬ê´„ì  AI ê·œì œë²•. 2024ë…„ 8ì›” ë°œíš¨, 2026ë…„ 8ì›” ê³ ìœ„í—˜ AI ì˜ë¬´ ì „ë©´ ì‹œí–‰ ì˜ˆì •. "
                           "ìœ„í—˜ ìˆ˜ì¤€ë³„ 4ë‹¨ê³„(ê¸ˆì§€Â·ê³ ìœ„í—˜Â·ì œí•œÂ·ìµœì†Œ) ë¶„ë¥˜. ìœ„ë°˜ ì‹œ ìµœëŒ€ 3,500ë§Œ ìœ ë¡œ ë˜ëŠ” ì „ ì„¸ê³„ ë§¤ì¶œ 7% ê³¼ì§•ê¸ˆ.",
            "source_url": "https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai",
            "impact_areas": ["Healthcare", "Finance", "Public Services", "Law Enforcement"],
            "is_trending": True,
        },
        # â”€â”€ ë¯¸êµ­ â”€â”€
        {
            "title": "US Executive Order on Safe, Secure, and Trustworthy AI",
            "policy_type": "Executive Order",
            "country": "United States",
            "status": "Active",
            "description": "ë°”ì´ë“  í–‰ì •ë¶€ì˜ AI í–‰ì •ëª…ë ¹(2023-10). ì´ì¤‘ ì‚¬ìš© AI ëª¨ë¸ì˜ ì•ˆì „ í…ŒìŠ¤íŠ¸ ë³´ê³  ì˜ë¬´, "
                           "AI ìƒì„± ì½˜í…ì¸  ì›Œí„°ë§ˆí¬ í‘œì¤€ ê°œë°œ, ì—°ë°© ì •ë¶€ AI ì‚¬ìš© ê°€ì´ë“œë¼ì¸ ìˆ˜ë¦½.",
            "source_url": "https://www.whitehouse.gov/ai",
            "impact_areas": ["Security", "Privacy", "Innovation", "National Security"],
            "is_trending": True,
        },
        # â”€â”€ ì¤‘êµ­ â”€â”€
        {
            "title": "ìƒì„±í˜• ì¸ê³µì§€ëŠ¥ ì„œë¹„ìŠ¤ ê´€ë¦¬ ì í–‰ ë°©ë²•",
            "policy_type": "Regulation",
            "country": "China",
            "status": "Active",
            "description": "2023ë…„ 8ì›” ì‹œí–‰. ìƒì„±í˜• AI ì„œë¹„ìŠ¤ ì œê³µ ì‹œ ì‚¬ì „ ë“±ë¡(ì•Œê³ ë¦¬ì¦˜ ë¹„ì•ˆ) ì˜ë¬´, "
                           "ì‚¬íšŒì£¼ì˜ í•µì‹¬ ê°€ì¹˜ ì¤€ìˆ˜, í•™ìŠµ ë°ì´í„° ì ë²•ì„± ë³´ì¥ ìš”êµ¬.",
            "source_url": "http://www.cac.gov.cn",
            "impact_areas": ["Content Moderation", "Data Governance", "Social Stability"],
            "is_trending": True,
        },
    ]

    def __init__(self):
        self.rss_feeds = {
            # Global
            "AI News": "https://www.artificialintelligence-news.com/feed/",
            "OECD AI Observatory": "https://oecd.ai/en/feed",
            "Brookings AI": "https://www.brookings.edu/topic/artificial-intelligence/feed/",
            # Korea
            "ê³¼ê¸°ì •í†µë¶€": "https://www.msit.go.kr/bbs/list.do?sCode=user&mId=113&mPid=238&bbsSeqNo=94&nttSeqNo=&pageIndex=1&searchOpt=ALL&searchTxt=ì¸ê³µì§€ëŠ¥",
        }

    @staticmethod
    def _strip_html(text: str) -> str:
        """HTML íƒœê·¸ ì œê±° + ì—”í‹°í‹° ë””ì½”ë”©."""
        if not text:
            return ""
        import html
        cleaned = re.sub(r"<[^>]+>", " ", text)
        cleaned = html.unescape(cleaned)
        cleaned = re.sub(r"\s+", " ", cleaned).strip()
        return cleaned

    @staticmethod
    def _is_korean_policy(country: str) -> bool:
        normalized = (country or "").strip().lower()
        return normalized in {"south korea", "korea", "kr", "í•œêµ­", "ëŒ€í•œë¯¼êµ­"}

    async def fetch_policy_news(self, max_results: int = 20) -> List[Dict]:
        """RSS í”¼ë“œì—ì„œ AI ì •ì±… ë‰´ìŠ¤ ìˆ˜ì§‘"""
        policies = []

        try:
            for source_name, feed_url in self.rss_feeds.items():
                try:
                    feed = feedparser.parse(feed_url)

                    for entry in feed.entries[:max_results]:
                        title = entry.get("title", "")
                        description = entry.get("summary", entry.get("description", ""))

                        # AI policy ê´€ë ¨ í‚¤ì›Œë“œ í•„í„°ë§
                        policy_keywords = ["regulation", "policy", "law", "act", "bill", "governance",
                                         "compliance", "framework", "legislation", "eu ai act"]

                        title_lower = title.lower()
                        desc_lower = description.lower()

                        is_policy_related = any(keyword in title_lower or keyword in desc_lower
                                               for keyword in policy_keywords)

                        if not is_policy_related:
                            continue

                        # ì˜í–¥ ì˜ì—­ ì¶”ì¶œ
                        impact_areas = self._extract_impact_areas(description)

                        policies.append({
                            "title": self._strip_html(title),
                            "policy_type": "News",
                            "country": "Global",
                            "status": "Proposed",
                            "description": self._strip_html(description)[:500],
                            "source_url": entry.get("link", ""),
                            "impact_areas": impact_areas,
                            "is_trending": True,
                        })

                        if len(policies) >= max_results:
                            break

                except Exception as e:
                    print(f"  âš ï¸ {source_name} RSS ì—ëŸ¬: {e}")
                    continue

            print(f"  âœ… {len(policies)}ê°œ AI ì •ì±… ë‰´ìŠ¤ ìˆ˜ì§‘")

        except Exception as e:
            print(f"  âŒ Policy RSS ì—ëŸ¬: {e}")
            return await self.fetch_sample_policies()

        # Always include curated policies alongside RSS-fetched ones
        curated = await self.fetch_sample_policies()
        return curated + policies

    def _extract_impact_areas(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì˜í–¥ ì˜ì—­ ì¶”ì¶œ"""
        areas = {
            "Healthcare": ["health", "medical", "hospital", "patient"],
            "Finance": ["bank", "finance", "financial", "trading"],
            "Education": ["education", "school", "university", "learning"],
            "Transportation": ["autonomous", "vehicle", "transport", "driving"],
            "Privacy": ["privacy", "data protection", "gdpr", "personal data"],
            "Security": ["security", "defense", "military", "surveillance"],
        }

        text_lower = text.lower()
        found_areas = []

        for area, keywords in areas.items():
            if any(keyword in text_lower for keyword in keywords):
                found_areas.append(area)

        return found_areas[:5] if found_areas else ["General"]

    async def fetch_sample_policies(self) -> List[Dict]:
        """Gemini deep research ê¸°ë°˜ íë ˆì´ì…˜ ì •ì±… ë°ì´í„° ë°˜í™˜"""
        print(f"ğŸ“¦ Loading {len(self.CURATED_POLICIES)} curated AI policies from research data")
        return self.CURATED_POLICIES

    async def save_to_db(self, items: List[Dict], db: AsyncSession) -> int:
        """ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        saved = 0
        ai_service = AISummaryService()
        for item in items:
            # HTML íƒœê·¸ ì œê±°
            if item.get("description"):
                item["description"] = self._strip_html(item["description"])
            if item.get("title"):
                item["title"] = self._strip_html(item["title"])
            url = item.get('source_url')
            country = item.get("country", "")

            # í•´ì™¸ ì •ì±…ì€ ì €ì¥ ì‹œì ì— í•œêµ­ì–´ ìš”ì•½ ìƒì„±
            if ai_service.model and (not self._is_korean_policy(country)) and not item.get("summary"):
                summary_data = await ai_service.summarize_policy(
                    title=item.get("title", ""),
                    description=item.get("description", ""),
                    policy_type=item.get("policy_type"),
                    impact_areas=item.get("impact_areas", []) or [],
                )
                if summary_data.get("summary"):
                    item["summary"] = summary_data["summary"]
                if summary_data.get("keywords"):
                    item["keywords"] = summary_data["keywords"]

            if url:
                result = await db.execute(select(AIPolicy).where(AIPolicy.source_url == url))
                existing = result.scalar_one_or_none()
                if not existing:
                    db.add(AIPolicy(**item))
                    saved += 1
                else:
                    for key, value in item.items():
                        if hasattr(existing, key) and value is not None:
                            setattr(existing, key, value)

                    if existing.title:
                        existing.title = self._strip_html(existing.title)
                    if existing.description:
                        existing.description = self._strip_html(existing.description)

                    if (
                        ai_service.model
                        and (not self._is_korean_policy(existing.country or ""))
                        and not existing.summary
                    ):
                        summary_data = await ai_service.summarize_policy(
                            title=existing.title,
                            description=existing.description or "",
                            policy_type=existing.policy_type,
                            impact_areas=existing.impact_areas or [],
                        )
                        if summary_data.get("summary"):
                            existing.summary = summary_data["summary"]
                        if summary_data.get("keywords"):
                            existing.keywords = summary_data["keywords"]
        await db.commit()
        return saved
