"""AI Conference ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤"""
import httpx
import feedparser
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, desc

from app.models.conference import AIConference
from app.config import get_settings


class ConferenceService:
    """AI Conference ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬"""

    # WikiCFP RSS feeds for AI-related conferences
    RSS_FEEDS = {
        "ai": "http://www.wikicfp.com/cfp/rss?cat=intelligence&t=c",
        "ml": "http://www.wikicfp.com/cfp/rss?cat=machine+learning&t=c",
        "cv": "http://www.wikicfp.com/cfp/rss?cat=computer+vision&t=c",
        "nlp": "http://www.wikicfp.com/cfp/rss?cat=natural+language&t=c",
    }

    # Well-known AI conferences
    MAJOR_CONFERENCES = {
        "NeurIPS": "A*",
        "ICML": "A*",
        "ICLR": "A*",
        "CVPR": "A*",
        "AAAI": "A*",
        "IJCAI": "A*",
        "ACL": "A*",
        "EMNLP": "A",
        "NAACL": "A",
        "ECCV": "A",
        "ICCV": "A*",
    }

    # Confirmed 2026 conference data from Gemini deep research (2026-02)
    CONFERENCES_2026 = {
        "AAAI 2026": {
            "full_name": "Association for the Advancement of Artificial Intelligence",
            "dates": "2026-01-20 ~ 2026-01-27",
            "start_date": "2026-01-20",
            "end_date": "2026-01-27",
            "location": "Singapore (Singapore Expo)",
            "tier": "A*",
            "topics": ["AI", "Robotics", "Agents"],
            "website": "https://aaai.org/conference/aaai/aaai-26/",
        },
        "ICLR 2026": {
            "full_name": "International Conference on Learning Representations",
            "dates": "2026-04-23 ~ 2026-04-27",
            "start_date": "2026-04-23",
            "end_date": "2026-04-27",
            "location": "Rio de Janeiro, Brazil",
            "tier": "A*",
            "topics": ["Deep Learning", "Neural Architecture"],
            "website": "https://iclr.cc/",
        },
        "CVPR 2026": {
            "full_name": "Computer Vision and Pattern Recognition",
            "dates": "2026-06-03 ~ 2026-06-07",
            "start_date": "2026-06-03",
            "end_date": "2026-06-07",
            "location": "Denver, CO, USA",
            "tier": "A*",
            "topics": ["Computer Vision", "Video Generation"],
            "website": "https://cvpr.thecvf.com/",
        },
        "ICML 2026": {
            "full_name": "International Conference on Machine Learning",
            "dates": "2026-07-06 ~ 2026-07-11",
            "start_date": "2026-07-06",
            "end_date": "2026-07-11",
            "location": "Seoul, South Korea",
            "tier": "A*",
            "topics": ["Machine Learning"],
            "website": "https://icml.cc/",
        },
        "KDD 2026": {
            "full_name": "Knowledge Discovery and Data Mining",
            "dates": "2026-08-09 ~ 2026-08-13",
            "start_date": "2026-08-09",
            "end_date": "2026-08-13",
            "location": "Jeju, South Korea (ICC Jeju)",
            "tier": "A*",
            "topics": ["Data Mining", "Applied Data Science"],
            "website": "https://kdd2026.kdd.org/",
        },
        "NeurIPS 2026": {
            "full_name": "Neural Information Processing Systems",
            "dates": "2026-12-06 ~ 2026-12-12",
            "start_date": "2026-12-06",
            "end_date": "2026-12-12",
            "location": "Sydney, Australia",
            "tier": "A*",
            "topics": ["Neural Networks", "ML"],
            "website": "https://neurips.cc/",
        },
    }

    def __init__(self):
        pass

    def get_confirmed_2026_conferences(self) -> List[Dict[str, Any]]:
        """
        Gemini deep researchë¡œ í™•ì¸ëœ 2026 ì»¨í¼ëŸ°ìŠ¤ ì •ë³´ ë°˜í™˜

        Returns:
            í™•ì¸ëœ 2026 ì»¨í¼ëŸ°ìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        conferences = []
        for name, data in self.CONFERENCES_2026.items():
            conf = {
                "conference_name": name,
                "conference_acronym": name.split(" ")[0],  # e.g., "AAAI" from "AAAI 2026"
                "full_name": data["full_name"],
                "website_url": data["website"],
                "dates": data["dates"],
                "start_date": data["start_date"],
                "end_date": data["end_date"],
                "location": data["location"],
                "year": 2026,
                "topics": data["topics"],
                "tier": data["tier"],
                "is_upcoming": self._is_upcoming_by_date_str(data["start_date"]),
                "source": "gemini_research_confirmed",
            }
            conferences.append(conf)
        return conferences

    def _is_upcoming_by_date_str(self, date_str: str) -> bool:
        """ë‚ ì§œ ë¬¸ìì—´ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ê°€ì˜¤ëŠ” ì»¨í¼ëŸ°ìŠ¤ì¸ì§€ í™•ì¸"""
        try:
            conf_date = datetime.strptime(date_str, "%Y-%m-%d")
            now = datetime.now()
            return now < conf_date < (now + timedelta(days=180))
        except Exception:
            return False

    async def fetch_wikicfp_conferences(self, max_results: int = 50, year: int = 2026) -> List[Dict[str, Any]]:
        """
        WikiCFP RSS í”¼ë“œì—ì„œ AI ì»¨í¼ëŸ°ìŠ¤ ì •ë³´ ìˆ˜ì§‘ + í™•ì¸ëœ 2026 ë°ì´í„° ë³‘í•©

        Args:
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            year: ìˆ˜ì§‘ ëŒ€ìƒ ì—°ë„ (ê¸°ë³¸ê°’: 2026)

        Returns:
            ì»¨í¼ëŸ°ìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        all_conferences = []

        # 1. í™•ì¸ëœ 2026 ì»¨í¼ëŸ°ìŠ¤ ë°ì´í„° ìš°ì„  ì¶”ê°€
        if year == 2026:
            confirmed = self.get_confirmed_2026_conferences()
            all_conferences.extend(confirmed)
            print(f"âœ… Loaded {len(confirmed)} confirmed 2026 conferences from research data")

        # 2. WikiCFP RSS í”¼ë“œì—ì„œ ì¶”ê°€ ìˆ˜ì§‘
        confirmed_acronyms = {c["conference_acronym"] for c in all_conferences}

        try:
            for category, feed_url in self.RSS_FEEDS.items():
                print(f"ğŸ“¡ Fetching {year} conferences from WikiCFP ({category})...")

                # feedparserëŠ” ë™ê¸° ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë¯€ë¡œ ì§ì ‘ ì‚¬ìš©
                feed = feedparser.parse(feed_url)

                for entry in feed.entries[:max_results]:
                    conference_data = self._parse_wikicfp_entry(entry, category, year_filter=year)
                    if conference_data:
                        # ì´ë¯¸ í™•ì¸ëœ ì»¨í¼ëŸ°ìŠ¤ëŠ” ì¤‘ë³µ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                        acronym = conference_data.get("conference_acronym")
                        if acronym and acronym in confirmed_acronyms:
                            continue
                        all_conferences.append(conference_data)

                print(f"âœ… Fetched entries from {category} (year={year})")

        except Exception as e:
            print(f"âŒ Error fetching WikiCFP conferences: {e}")

        return all_conferences[:max_results]

    def _parse_wikicfp_entry(self, entry: Any, category: str, year_filter: int = 2026) -> Optional[Dict[str, Any]]:
        """
        WikiCFP RSS entry íŒŒì‹±

        Args:
            entry: feedparser entry ê°ì²´
            category: ì¹´í…Œê³ ë¦¬ (ai, ml, cv, nlp)
            year_filter: ìˆ˜ì§‘ ëŒ€ìƒ ì—°ë„ (ê¸°ë³¸ê°’: 2026)

        Returns:
            íŒŒì‹±ëœ ì»¨í¼ëŸ°ìŠ¤ ì •ë³´ (ì—°ë„ í•„í„° ë¯¸í†µê³¼ ì‹œ None)
        """
        try:
            title = entry.get("title", "")
            link = entry.get("link", "")
            description = entry.get("summary", "")

            # ì œëª©ì—ì„œ ì»¨í¼ëŸ°ìŠ¤ ì•½ì–´ ì¶”ì¶œ ì‹œë„
            acronym = self._extract_acronym(title)

            # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ (WikiCFP í˜•ì‹ íŒŒì‹± í•„ìš”)
            # ì˜ˆ: "Submission Deadline: Jan 15, 2026"
            submission_deadline = self._extract_date_from_text(description, "submission")

            # Phase 2: ì—°ë„ í•„í„° - ì œëª© ë˜ëŠ” ë§ˆê°ì¼ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ìƒ ì—°ë„ë§Œ ìˆ˜ì§‘
            title_has_year = str(year_filter) in title
            deadline_matches = (
                submission_deadline is not None
                and submission_deadline.year == year_filter
            )
            if not title_has_year and not deadline_matches:
                # ì—°ë„ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ í†µê³¼ (ë°ì´í„° ì†ì‹¤ ë°©ì§€)
                if submission_deadline is not None:
                    return None

            # ê¸°ë³¸ ì •ë³´ êµ¬ì„±
            conference_data = {
                "conference_name": title,
                "conference_acronym": acronym,
                "website_url": link,
                "submission_deadline": submission_deadline,
                "year": year_filter,
                "topics": [category.upper()],
                "tier": self.MAJOR_CONFERENCES.get(acronym, "B") if acronym else "B",
                "is_upcoming": self._is_upcoming(submission_deadline),
            }

            return conference_data

        except Exception as e:
            print(f"âš ï¸ Error parsing WikiCFP entry: {e}")
            return None

    def _extract_acronym(self, title: str) -> Optional[str]:
        """ì œëª©ì—ì„œ ì»¨í¼ëŸ°ìŠ¤ ì•½ì–´ ì¶”ì¶œ"""
        import re

        # ê´„í˜¸ ì•ˆì˜ ì•½ì–´ ì°¾ê¸°: "International Conference on XYZ (ICXYZ) 2026"
        match = re.search(r'\(([A-Z]+)\)', title)
        if match:
            return match.group(1)

        # ì•Œë ¤ì§„ ì»¨í¼ëŸ°ìŠ¤ëª…ì´ ìˆëŠ”ì§€ í™•ì¸
        for conf_name in self.MAJOR_CONFERENCES.keys():
            if conf_name in title.upper():
                return conf_name

        return None

    def _extract_date_from_text(self, text: str, date_type: str = "submission") -> Optional[datetime]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ ì¶”ì¶œ

        Args:
            text: íŒŒì‹±í•  í…ìŠ¤íŠ¸
            date_type: ë‚ ì§œ ìœ í˜• (submission, notification, start, end)

        Returns:
            ì¶”ì¶œëœ datetime ê°ì²´
        """
        import re
        from dateutil import parser as date_parser

        try:
            # ë‚ ì§œ íŒ¨í„´ ì°¾ê¸°
            patterns = {
                "submission": r"(?:submission|deadline):\s*([A-Za-z]+\s+\d{1,2},?\s+\d{4})",
                "notification": r"notification:\s*([A-Za-z]+\s+\d{1,2},?\s+\d{4})",
                "start": r"(?:start|conference):\s*([A-Za-z]+\s+\d{1,2},?\s+\d{4})",
            }

            pattern = patterns.get(date_type, patterns["submission"])
            match = re.search(pattern, text, re.IGNORECASE)

            if match:
                date_str = match.group(1)
                return date_parser.parse(date_str)

        except Exception as e:
            print(f"âš ï¸ Date parsing error: {e}")

        return None

    def _is_upcoming(self, deadline: Optional[datetime]) -> bool:
        """ë§ˆê°ì¼ì´ ë‹¤ê°€ì˜¤ëŠ” ì»¨í¼ëŸ°ìŠ¤ì¸ì§€ í™•ì¸"""
        if not deadline:
            return False

        now = datetime.now()
        # ë§ˆê°ì¼ì´ í˜„ì¬ë¡œë¶€í„° 6ê°œì›” ì´ë‚´ë©´ upcoming
        return now < deadline < (now + timedelta(days=180))

    async def save_to_db(
        self, conferences: List[Dict[str, Any]], db: AsyncSession
    ) -> int:
        """
        ì»¨í¼ëŸ°ìŠ¤ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥

        Args:
            conferences: ì»¨í¼ëŸ°ìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜

        Returns:
            ì €ì¥ëœ í•­ëª© ìˆ˜
        """
        saved_count = 0

        for conf_data in conferences:
            try:
                # ì¤‘ë³µ í™•ì¸ (URL ê¸°ì¤€)
                website_url = conf_data.get("website_url")
                if not website_url:
                    continue

                result = await db.execute(
                    select(AIConference).where(AIConference.website_url == website_url)
                )
                existing = result.scalar_one_or_none()

                if existing:
                    # ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
                    for key, value in conf_data.items():
                        if hasattr(existing, key) and value is not None:
                            setattr(existing, key, value)
                    print(f"ğŸ“ Updated: {conf_data.get('conference_name', 'Unknown')}")
                else:
                    # ìƒˆ í•­ëª© ìƒì„±
                    new_conference = AIConference(**conf_data)
                    db.add(new_conference)
                    saved_count += 1
                    print(f"âœ¨ Created: {conf_data.get('conference_name', 'Unknown')}")

                await db.commit()

            except Exception as e:
                await db.rollback()
                print(f"âŒ Error saving conference: {e}")
                continue

        return saved_count

    async def get_conferences(
        self, db: AsyncSession, skip: int = 0, limit: int = 20,
        upcoming_only: bool = False, year: Optional[int] = None
    ) -> List[AIConference]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì»¨í¼ëŸ°ìŠ¤ ëª©ë¡ ì¡°íšŒ

        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            skip: ê±´ë„ˆë›¸ í•­ëª© ìˆ˜
            limit: ë°˜í™˜í•  ìµœëŒ€ í•­ëª© ìˆ˜
            upcoming_only: ë‹¤ê°€ì˜¤ëŠ” ì»¨í¼ëŸ°ìŠ¤ë§Œ ì¡°íšŒ
            year: ì—°ë„ í•„í„°

        Returns:
            ì»¨í¼ëŸ°ìŠ¤ ëª©ë¡
        """
        query = select(AIConference)

        if upcoming_only:
            query = query.where(AIConference.is_upcoming == True)

        # Phase 2: ì—°ë„ í•„í„°
        if year is not None:
            query = query.where(AIConference.year == year)

        query = query.order_by(desc(AIConference.submission_deadline)).offset(skip).limit(limit)

        result = await db.execute(query)
        return result.scalars().all()
