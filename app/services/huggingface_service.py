"""Hugging Face ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤"""
import httpx
from typing import List, Dict, Any, Optional
from datetime import datetime, timezone
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from app.config import get_settings
from app.db_compat import has_column, has_columns
from app.models.huggingface import HuggingFaceModel
from app.services.ai_summary_service import AISummaryService

settings = get_settings()

# Hugging Face API ì—”ë“œí¬ì¸íŠ¸
HF_API_BASE = "https://huggingface.co/api"
HF_MODELS_ENDPOINT = f"{HF_API_BASE}/models"


class HuggingFaceService:
    """Hugging Face API ì—°ë™ ì„œë¹„ìŠ¤"""

    # Pipeline tag Korean mapping from ChatGPT deep research (2026-02)
    PIPELINE_TAG_KO = {
        "text-generation": "í…ìŠ¤íŠ¸ ìƒì„±",
        "text-to-image": "ì´ë¯¸ì§€ ìƒì„±",
        "text-classification": "í…ìŠ¤íŠ¸ ë¶„ë¥˜",
        "fill-mask": "ë‹¨ì–´ ì±„ìš°ê¸°",
        "translation": "ë²ˆì—­",
        "speech-to-text": "ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜",
        "text-to-speech": "í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜",
        "image-classification": "ì´ë¯¸ì§€ ë¶„ë¥˜",
        "object-detection": "ê°ì²´ íƒì§€",
        "image-segmentation": "ì´ë¯¸ì§€ ë¶„í• ",
        "question-answering": "ì§ˆì˜ ì‘ë‹µ",
        "summarization": "ìš”ì•½",
        "audio-classification": "ì˜¤ë””ì˜¤ ë¶„ë¥˜",
        "text-to-video": "í…ìŠ¤íŠ¸-íˆ¬-ë¹„ë””ì˜¤",
        "feature-extraction": "íŠ¹ì§• ì¶”ì¶œ",
    }

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or settings.huggingface_api_key
        self.headers = {}
        if self.api_key:
            self.headers["Authorization"] = f"Bearer {self.api_key}"

    @staticmethod
    async def _has_task_ko_column(db: AsyncSession) -> bool:
        """ëŸ°íƒ€ì„ DBì— task_ko ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (êµ¬ë²„ì „ ìŠ¤í‚¤ë§ˆ í˜¸í™˜)."""
        return await has_column(db, "huggingface_models", "task_ko")

    async def fetch_trending_models(
        self,
        limit: int = 20,
        task: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """
        Hugging Faceì—ì„œ íŠ¸ë Œë”© ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°

        Args:
            limit: ê°€ì ¸ì˜¬ ëª¨ë¸ ê°œìˆ˜
            task: íƒœìŠ¤í¬ í•„í„° (ì˜ˆ: text-generation, image-generation)

        Returns:
            ëª¨ë¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        # sort=likes better reflects trending interest than total downloads
        params = {
            "sort": "likes",
            "direction": "-1",
            "limit": limit,
        }

        if task:
            params["pipeline_tag"] = task

        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.get(
                    HF_MODELS_ENDPOINT,
                    params=params,
                    headers=self.headers,
                )
                response.raise_for_status()
                return response.json()
            except Exception as e:
                print(f"âŒ Hugging Face API ì—ëŸ¬: {e}")
                return []

    async def fetch_recent_models(
        self,
        limit: int = 20,
        task: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """
        Hugging Faceì—ì„œ ìµœì‹  ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°

        Args:
            limit: ê°€ì ¸ì˜¬ ëª¨ë¸ ê°œìˆ˜
            task: íƒœìŠ¤í¬ í•„í„°

        Returns:
            ëª¨ë¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        params = {
            "sort": "lastModified",
            "limit": limit,
        }

        if task:
            params["pipeline_tag"] = task

        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.get(
                    HF_MODELS_ENDPOINT,
                    params=params,
                    headers=self.headers,
                )
                response.raise_for_status()
                return response.json()
            except Exception as e:
                print(f"âŒ Hugging Face API ì—ëŸ¬: {e}")
                return []

    def parse_model_data(self, raw_model: Dict[str, Any]) -> Dict[str, Any]:
        """
        Hugging Face API ì‘ë‹µì„ ìš°ë¦¬ ëª¨ë¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
            raw_model: HF API ì›ë³¸ ë°ì´í„°

        Returns:
            ë³€í™˜ëœ ëª¨ë¸ ë°ì´í„°
        """
        # ê¸°ë³¸ ì •ë³´
        model_id = raw_model.get("id", "")
        model_name = raw_model.get("cardData", {}).get("name") or model_id.split("/")[-1]
        author = raw_model.get("author") or model_id.split("/")[0]

        # íƒœìŠ¤í¬ ì •ë³´
        pipeline_tag = raw_model.get("pipeline_tag")
        tags = raw_model.get("tags", [])

        # í†µê³„
        downloads = raw_model.get("downloads", 0)
        likes = raw_model.get("likes", 0)

        # ë©”íƒ€ë°ì´í„°
        library_name = raw_model.get("library_name")
        last_modified = raw_model.get("lastModified")
        if last_modified:
            try:
                last_modified = datetime.fromisoformat(last_modified.replace("Z", "+00:00"))
            except Exception:
                last_modified = None

        # ëª¨ë¸ ìƒì„±ì¼ (lastModifiedëŠ” README ìˆ˜ì •ì—ë„ ê°±ì‹ ë˜ë¯€ë¡œ createdAt ì‚¬ìš©)
        created_at = raw_model.get("createdAt")
        if created_at:
            try:
                created_at = datetime.fromisoformat(created_at.replace("Z", "+00:00"))
            except Exception:
                created_at = None

        # URL
        url = f"https://huggingface.co/{model_id}"

        # ì„¤ëª… (cardì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        description = None
        card_data = raw_model.get("cardData", {})
        if isinstance(card_data, dict):
            description = card_data.get("description") or card_data.get("summary")

        # Korean pipeline tag for frontend display
        task_ko = self.PIPELINE_TAG_KO.get(pipeline_tag, pipeline_tag) if pipeline_tag else None

        return {
            "model_id": model_id,
            "model_name": model_name,
            "author": author,
            "description": description,
            "task": pipeline_tag,
            "task_ko": task_ko,
            "tags": tags,
            "library_name": library_name,
            "downloads": downloads,
            "likes": likes,
            "url": url,
            "last_modified": last_modified,
            "created_at": created_at,
        }

    async def save_models_to_db(
        self,
        models_data: List[Dict[str, Any]],
        db: AsyncSession,
        is_trending: bool = False,
    ) -> int:
        """
        ëª¨ë¸ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥

        Args:
            models_data: ëª¨ë¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            is_trending: íŠ¸ë Œë”© ëª¨ë¸ ì—¬ë¶€

        Returns:
            ì €ì¥ëœ ëª¨ë¸ ê°œìˆ˜
        """
        saved_count = 0
        ai_service = AISummaryService()
        column_flags = await has_columns(
            db,
            "huggingface_models",
            ["task_ko", "is_archived", "archived_at"],
        )
        has_task_ko_column = column_flags["task_ko"]
        has_archive_columns = (
            column_flags["is_archived"] and column_flags["archived_at"]
        )

        for model_data in models_data:
            parsed_data = self.parse_model_data(model_data)
            if not has_task_ko_column:
                parsed_data.pop("task_ko", None)

            # ê¸°ì¡´ ëª¨ë¸ í™•ì¸
            query = select(HuggingFaceModel).where(
                HuggingFaceModel.model_id == parsed_data["model_id"]
            )
            result = await db.execute(query)
            existing_model = result.scalar_one_or_none()

            if existing_model:
                # ì—…ë°ì´íŠ¸
                for key, value in parsed_data.items():
                    if hasattr(existing_model, key):
                        setattr(existing_model, key, value)
                existing_model.is_trending = is_trending
                if has_archive_columns:
                    existing_model.is_archived = False
                    existing_model.archived_at = None
                existing_model.collected_at = datetime.now(timezone.utc)
                # ê¸°ì¡´ ëª¨ë¸ì— í•œê¸€ ìš”ì•½ì´ ì—†ìœ¼ë©´ ìƒì„±
                if ai_service.model and not getattr(existing_model, "summary", None):
                    summary_data = await ai_service.summarize_huggingface_model(
                        model_name=existing_model.model_id,
                        description=existing_model.description,
                        task=existing_model.task,
                        tags=existing_model.tags or [],
                    )
                    if summary_data.get("summary"):
                        existing_model.summary = summary_data["summary"]
            else:
                # Gemini í•œê¸€ ìš”ì•½ ìƒì„±
                if ai_service.model:
                    summary_data = await ai_service.summarize_huggingface_model(
                        model_name=parsed_data.get("model_id", ""),
                        description=parsed_data.get("description"),
                        task=parsed_data.get("task"),
                        tags=parsed_data.get("tags", []),
                    )
                    if summary_data.get("summary"):
                        parsed_data["summary"] = summary_data["summary"]

                # ìƒˆë¡œ ìƒì„±
                new_model = HuggingFaceModel(
                    **parsed_data,
                    is_trending=is_trending,
                )
                db.add(new_model)
                saved_count += 1

        await db.commit()
        return saved_count

    async def collect_trending_models(
        self,
        db: AsyncSession,
        limit: int = 20,
    ) -> Dict[str, Any]:
        """
        íŠ¸ë Œë”© ëª¨ë¸ ìˆ˜ì§‘ ë° ì €ì¥

        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            limit: ìˆ˜ì§‘í•  ëª¨ë¸ ê°œìˆ˜

        Returns:
            ìˆ˜ì§‘ ê²°ê³¼
        """
        print(f"ğŸ” Hugging Face íŠ¸ë Œë”© ëª¨ë¸ {limit}ê°œ ìˆ˜ì§‘ ì‹œì‘...")

        # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        models_data = await self.fetch_trending_models(limit=limit)

        if not models_data:
            print("âš ï¸  ê°€ì ¸ì˜¨ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {"success": False, "count": 0}

        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        saved_count = await self.save_models_to_db(
            models_data,
            db,
            is_trending=True,
        )

        print(f"âœ… {saved_count}ê°œ ì‹ ê·œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
        return {
            "success": True,
            "count": saved_count,
            "total_fetched": len(models_data),
        }

    async def collect_recent_models(
        self,
        db: AsyncSession,
        limit: int = 20,
    ) -> Dict[str, Any]:
        """
        ìµœì‹  ëª¨ë¸ ìˆ˜ì§‘ ë° ì €ì¥

        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            limit: ìˆ˜ì§‘í•  ëª¨ë¸ ê°œìˆ˜

        Returns:
            ìˆ˜ì§‘ ê²°ê³¼
        """
        print(f"ğŸ” Hugging Face ìµœì‹  ëª¨ë¸ {limit}ê°œ ìˆ˜ì§‘ ì‹œì‘...")

        # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        models_data = await self.fetch_recent_models(limit=limit)

        if not models_data:
            print("âš ï¸  ê°€ì ¸ì˜¨ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {"success": False, "count": 0}

        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        saved_count = await self.save_models_to_db(models_data, db)

        print(f"âœ… {saved_count}ê°œ ì‹ ê·œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
        return {
            "success": True,
            "count": saved_count,
            "total_fetched": len(models_data),
        }
